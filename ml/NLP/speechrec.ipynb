{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f77e2387-3529-4a16-b36e-e542b203a53f",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "(unicode error) 'unicodeescape' codec can't decode bytes in position 29-30: truncated \\xXX escape (2053190756.py, line 16)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[2], line 16\u001b[1;36m\u001b[0m\n\u001b[1;33m    \"X\":\"D:\\Academics\\Machine Learning\\x.wav\",\u001b[0m\n\u001b[1;37m                                             ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m (unicode error) 'unicodeescape' codec can't decode bytes in position 29-30: truncated \\xXX escape\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import librosa\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import sounddevice as sd\n",
    "import soundfile as sf\n",
    "#Extract the features (HFCC)\n",
    "def extract_features(file_path):\n",
    "    y, sr=librosa.load(file_path, duration-3) #loads the audio file into the y: sound and sr: sampling rate, 3 seconds\n",
    "    mfcc=librosa.feature.mfcc(y-y, sr-sr,n_mfcc-13) #NFCC capture the tone, pitch and timbre of a voice,\n",
    "                                                    # y is the parameter, the other y is value a of amplitude,\n",
    "                                                    #sr is the parameter, the other st is the value of sample rate.\n",
    "    return np.mean(mfcc.T,axis=0) #It averages the MFCC over time, giving a fixed Lenght feature.\n",
    "#Training data\n",
    "#Audio samples of known speakers\n",
    "train_files={\n",
    "\"X\":\"D:\\Academics\\Machine Learning\\x.wav\",\n",
    "\"Y\":\"D:\\Academics Machine Learningly.wav\",\n",
    "}\n",
    "x,y=[],[]\n",
    "for speaker, file in train_files.items():\n",
    "    features-extract_features(file)\n",
    "    x.append(features)\n",
    "    y.append(features)\n",
    "#Train the classifier (KNN)\n",
    "model=KNeighborsClassifier(n_neighbors-1)\n",
    "model.fit(x,y)\n",
    "#Record the audio (Live)\n",
    "duration=3 #seconds\n",
    "print(\"Speak now(you have 3 seconds)...\")\n",
    "#Record from microphone\n",
    "recording=sd.res(int(duration 44100),samplerate 44100, channels-1)\n",
    "sf=wait()#wolt until recording is finished.\n",
    "#Save recorded file\n",
    "test file=\"test live.wav\"\n",
    "sf.write(test_file, recording, 44100)\n",
    "test features=extract_features (test_file)\n",
    "predicting_speaker=model.predict([test_features]), [0]\n",
    "print(\"Predicted Speaker:\", predicting_speaker)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "66fc822a-e28f-4f9c-86d8-4b041ff3b833",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import sounddevice as sd\n",
    "sr=44100\n",
    "d=1.0\n",
    "# freqs=300\n",
    "f=[200,300,100,200]\n",
    "for i in f:\n",
    "    t=np.linspace(0,d,int(sr*d),endpoint=False)\n",
    "    y=0.5*np.sin(2*np.pi*i*t)\n",
    "    sd.play(y,sr)\n",
    "    sd.wait()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "74bca750-aa47-4439-a382-5d5c2dfcb67f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import sounddevice as sd\n",
    "\n",
    "def play_tones(freq_list, duration=0.2, sr=44100):\n",
    "    for freq in freq_list:\n",
    "        t = np.linspace(0, duration, int(sr * duration), endpoint=False)\n",
    "        y = 0.5 * np.sin(2 * np.pi * freq * t)\n",
    "        \n",
    "        sd.play(y, sr)\n",
    "        sd.wait()\n",
    "\n",
    "# Example usage:\n",
    "f = [200,200,300,100,200,300,800,400,50,440,500,100,600,200,300,200,200,300,100,200,300,800,400,50,440,500,100,600,200,300,200,200,300,100,200,300,800,400,50,440,500,100,600,200,300,200,200,300,100,200,300,800,400,50,440,500,100,600,200,300]\n",
    "play_tones(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f101dd95-55cd-4d78-940f-1b08ccd6ad04",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import sounddevice as sd\n",
    "\n",
    "def play_tones(freq_list, duration=0.5, sr=44100):\n",
    "    for freq in freq_list:\n",
    "        t = np.linspace(0, duration, int(sr * duration), endpoint=False)\n",
    "        y = 0.5 * np.sin(2 * np.pi * freq * t)\n",
    "        \n",
    "        sd.play(y, sr)\n",
    "        sd.wait()\n",
    "\n",
    "# Example usage:\n",
    "f = [261, 261, 293, 261, 349, 329,\n",
    "  261, 261, 293, 261, 392, 349,\n",
    "  261, 261, 523, 440, 349, 329, 293,\n",
    "  466, 466, 440, 349, 392, 349]\n",
    "play_tones(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f0d8915b-4e20-4fe2-bfc2-3c1e68df9045",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import sounddevice as sd\n",
    "\n",
    "def play_tones(freq_list, duration=0.5, sr=44100):\n",
    "    for freq in freq_list:\n",
    "        t = np.linspace(0, duration, int(sr * duration), endpoint=False)\n",
    "        y = 0.5 * np.sin(2 * np.pi * freq * t)\n",
    "        \n",
    "        sd.play(y, sr)\n",
    "        sd.wait()\n",
    "\n",
    "# Example usage:\n",
    "f = [329.63, 293.66, 261.63, 293.66,\n",
    "    329.63, 329.63, 329.63,\n",
    "    293.66, 293.66, 293.66,\n",
    "    329.63, 392.00, 392.00]\n",
    "play_tones(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "84d1dfbd-3bb8-41b5-9eb4-f12036507222",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import sounddevice as sd\n",
    "\n",
    "def play_tones(freq_list, duration=0.5, sr=44100):\n",
    "    for freq in freq_list:\n",
    "        t = np.linspace(0, duration, int(sr * duration), endpoint=False)\n",
    "        y = 0.5 * np.sin(2 * np.pi * freq * t)\n",
    "        \n",
    "        sd.play(y, sr)\n",
    "        sd.wait()\n",
    "\n",
    "# Example usage:\n",
    "f = [261.63, 261.63, 293.66, 329.63, 329.63, 349.23,\n",
    "    392.00, 440.00, 493.88, 523.25]\n",
    "play_tones(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f35eb8a-e944-4f28-953e-83469f63a17a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
